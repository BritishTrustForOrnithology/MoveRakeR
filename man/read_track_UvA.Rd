% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/read_track.R
\name{read_track_UvA}
\alias{read_track_UvA}
\title{Reading in animal tracking data from the University of Amsterdam Bird Tracking (UvA-BiTS) database.}
\usage{
read_track_UvA(
  TagID,
  start = NULL,
  end = NULL,
  dropsat = FALSE,
  dropsats = 3,
  flt_switch = FALSE,
  mindata = 5,
  pressure = FALSE,
  p4s = 3035,
  verbose = TRUE
)
}
\arguments{
\item{TagID}{The individual tag identifier from the UvA-BiTS database.}

\item{start}{The start time to delineate subsets of the total data for the individual in UTC.}

\item{end}{The end time to delineate subsets of the total data for the individual in UTC.
The start and end times must be give in the format "2014-06-25 15:20:23".
Arguments \emph{start} and \emph{end} default to NULL, reading in the entire track
of the animal and must be given in' \emph{character()} format, which are then converted to
\code{base::POSIXct} format within the \code{read_track_MB} function. Functionality is also
available for situations where only one or other of start and end need to be specified,
with the the other defaulting to NULL. NOTE: THE FUNCTION WILL RETURN AN ERROR IF NO DATA ARE FOUND BETWEEN START AND END TIMES SPECIFIED.}

\item{dropsat}{Logical defaults to FALSE. This indicates whether to drop GPS fixes with satellites below
the \emph{dropsats} threshold. It is suggested the user do not change these
from FALSE but instead use the function \code{\link{clean_GPS}}.}

\item{dropsats}{Numeric value indicating a threshold for satellite retention.}

\item{mindata}{This specifies a minimum number of rows of data for the individual
to be retained and is a form of cleaning, but here is retained to exclude reading
in data from animals with too few data deemed unusable for analysis.
Defaults to mindata = 5. It can of course be set to zero if a completely raw dataset.}

\item{pressure}{logical defaulting to FALSE, but if set to TRUE, the function will look to
see if there are any pressure data for the tag and date-time range, and merge it in. Note the data
can also be extracted using function \code{\link{read_pressure_UvA}} independently. If TRUE,
the "pressure" and "temperature" columns are overwritten by the data in the UvA pressure database view,
taking the form of averages of no. data points collected by the pressure sensor. Pressure units are in MB
and temperature in degC. A warning is returned if no pressure data are found if TRUE is specified.}

\item{p4s}{A coordinate reference system argument using \code{sf::st_crs()}, thus the user just needs to enter in an epsg value, default = 3035.
The lat-longs extracted from the Movebank database will be projected via this CRS and stored in two new columns
\emph{X} and \emph{Y} (note capitilisation). Note however, that further functions
give options to change this if you wish in due course, and the user of course do all point-level manipulation
outside the functions if they so wish anyway. Argument Defaults to BNG using epsg string \code{CRS("+init=epsg:27700")}.}

\item{flt_switch.}{logical argument, set to FALSE whether to retain
Movebank data erroneous flt_switch values, instead being dealt with in the
\code{\link{clean_GPS}} function.}
}
\value{
The final data outputted for individual animals is a \code{Track and data.frame} object of 29 variables for each
TagID; Type, TagID, DateTime, speed_2d, speed_3d, traj_speed, latitude, longitude,
X, Y, dist, dt, satellites_used, gps_fixtime, gps.pdop, gps.hdop, altitude,
altitude_agl, h_accuracy, v_accuracy, pressure, temperature, x_speed, y_speed,
z_speed, speed_accuracy, direction, location and flt_switch.
It is assumed here the user will be familiar with most of these.
You will notice that for Movebank and data downloaded from the University of Amsterdam
i.e. from different sources, will have columns of all NAs for some variables
that were in one database but not another. This alignment has meant the
inclusion of missing variables in those cases. For example UvA has a gps.pdop
value but Movetech has gps.hdop. Note also variables may differ to their
original truly "raw" naming convention in stored databases. The output here is
to align and simplify for further analysis. All time units are in seconds
and distances in metres, speeds in m/s. Importantly "location" refers to the
individual row.name identifier in respective databases, so that no matter what
data are extracted in this function, the saved data can be matched back and if
necessary recreated through the location variable if need be. This is important
for data that is continually being updated remotely and particularly if you
are working with the full data downloaded from animals up to very present.
Data at the individual level are always provided as a \code{Track} class, and for multiple
TagIDs, a \code{TrackStack} object is returned. Note, read in functions do not currently support
\code{TrackMultiStack} objects (i.e. the higher level listed class of \code{TrackStack} objects).
For \code{TrackMultiStack} objects, \code{TrackStack} object should be concatenated and coerced using \code{\link{track_multi_stack}}.
Names of each animal are provided for \code{Track} lists.
}
\description{
Connect and download tracking data directly from the UvA-BiTS phpPGAdmin SQL database.
}
\details{
At the core of this function is the desire to have wrapped flexibility
to extract sections of data across multiple individuals from specific
repositories. \code{read_track_UvA} along with its sister function \code{read_track_MB}
is therefore designed to do just that, so that a "control file"
i.e. with static start and end date-times for TagIDs can be used as a lookup table,
to extract the necessary data with ease. WARNING: \code{read_track_UvA}
requires access to the UvA-BiTS database in the first place, and further, it is
possible within these read in functions to extract large amounts of data. It is therefore advisable
to make as few direct calls to the databases and extract the data needed to be stored
and then read in again for subsequent analytical steps.

\code{read_track_UvA} uses an ODBC connection to establish a link with the UvA-BiTS
database. \strong{WARNING: THIS MUST BE SET UP FIRST BEFORE USING THIS FUNCTION}
and of course you must have prior access to the UvA-BiTS system with a username and password. Steps to do
this are provided here: \url{https://gitlab.com/uva_ibed_ame/uva-bits/-/wikis/How-to-access-the-e-Ecology-database}.
Extraction of GPS positional data from the database is made using R library \code{RODBC}
and the user must also first establish the database connection in their global environment
named as object \strong{'db'}, specifying whet the connection was named as in the help file steps above:
in this case called "GPS", using \code{RODBC::odbcConnect("GPS")}. See examples.

\code{read_track_UvA} then uses \code{RODBC} to construct SQL statements. Along with it's sister function \code{\link{read_track_MB}},
\code{read_track_UvA} is designed to extract GPS positional data on the fly in an efficient manner and to directly coerce
the resultant \code{base::data.frames} objects to \code{Track}, \code{TrackStack} and \code{TrackMultiStack} classes.
The user can also specify \emph{start} and and \emph{end} DateTimes (see below)
to specify subsections from the entire dataset available in repositories for individual
animals. R library \code{adehabitatLT:as.:traj} is also called to add a trajectory speed to the dataset
between fixes, along with a "dt" time difference (secs) and distance (m) between
fixes.

There are other arguments included in this function for cleaning, but these have
been transferred to the function \code{\link{clean_GPS}} function although they
are retained here are set to FALSE (see Arguments).
}
\examples{

db_file <- "GPS" # what you named the ODBC link on set up
db <- RODBC::odbcConnect(db_file) # currently required "db" to be named globally

## Example using direct calls to UvA-BiTS database using SQL coding for date-time start and ends per animal
# Note, you can extract multiple birds with the same start-ends this way too
TagID <- "('1','2','3')" # Tag (bird) ID's replace with your actual IDs
sttime <- "'2020-05-30 17:00:00'"
entime <- "'2020-06-02 17:00:00'"
data <- RODBC::sqlQuery(db, query =
                   paste(
                     "select", "device_info_serial, date_time, latitude, longitude, altitude, pressure, temperature, satellites_used, gps_fixtime, positiondop, h_accuracy, v_accuracy, x_speed, y_speed, z_speed, speed_accuracy, location, userflag, speed_3d, speed_2d, direction, altitude_agl",
                    "from", "gps.ee_tracking_speed_limited", "where",
                    "device_info_serial", "in", TagID,
                    "and",
                    "date_time >=", sttime,
                    "and",
                    "date_time <=", entime)
)

## Using read_track_UvA - read in three birds with different start/end times in 2016
TagID <- "('1','2','3')"
start = c("2016-06-01 13:53:50", "2016-06-15 12:22:13", "2016-06-05 08:07:23") # e.g. using specific starts/ends per bird
end = c("2016-07-15 09:17:14", "2016-07-20 01:08:58", "2016-07-18 14:22:45")
dataUvA <- read_track_UvA(TagID,start=start,end=end)

### testing pressure as well - if available this will be extracted and added to the GPS dataset
TagID <- "('1','2','3')"
start = c("2020-06-01 13:53:50", "2020-06-01 12:22:13", "2020-06-05 08:07:23")
end = c("2020-07-15 09:17:14", "2020-07-20 01:08:58", "2020-07-18 14:22:45")
data_pr <- read_track_UvA(TagID=TagID,start=start,end=end,pressure = TRUE)

# comparing numbers of records and extraction through read_pressure_UvA (one bird)
dataPr <- read_track_UvA(TagID='1',start="2020-06-01 13:53:50",end="2020-07-15 09:17:14",pressure=TRUE)
dataPr2 <- read_pressure_UvA(TagID='1',start="2020-06-01 13:53:50",end="2020-07-15 09:17:14")

}
\seealso{
\link{read_track_MB}, \link{read_pressure_UvA}, \link{read_accn_UvA}
}
